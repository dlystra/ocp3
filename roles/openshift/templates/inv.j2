# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd

# These are all the tags we give in dynamic inventory
# Now tie the abbreviated names to the tag_Type names
[nodes]
{% for m in ocp_masters %}
{{ m }} openshift_node_group_name='node-config-master'
{% endfor %}
{% for i in ocp_infras %}
{{ i }} openshift_node_group_name='node-config-infra'
{% endfor %}
{% for a in ocp_apps %}
{{ a }} openshift_node_group_name='node-config-compute'
{% endfor %}

[etcd]
{% for m in ocp_masters %}
{{ m }}
{% endfor %}

[masters]
{% for m in ocp_masters %}
{{ m }}
{% endfor %}

[infra]
{% for i in ocp_infras %}
{{ i }}
{% endfor %}

# Set variables common for all OSEv3 hosts
[OSEv3:vars]

#Inventory File Variables
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Set the image registry URL.  This is where OpenShift will pull all of the necessary images.
# If using registry.access.redhat.com or registry.redhat.io, make sure to update `openshift_docker_blocked_registries` below.
# Note that registry.access.redhat.com is depercated in favor of registry.redhat.io
image_registry={{ registry_hostname }}:5000

#OpenShift Environment
openshift_environment=development
#=======================================================================

# SSH user, this user should allow ssh based auth without requiring a
# password. If using ssh key based auth, then the key should be managed by an
# ssh agent.
ansible_user=ec2-user

# If ansible_user is not root, ansible_become must be set to true and the
# user must be configured for passwordless sudo
ansible_become=yes


# Debug level for all OpenShift components (Defaults to 2)
debug_level=2

#TIP May have to toggle these depending on machine sizes
#openshift_disable_check=cpu_availability,memory_availability,disk_availability,docker_storage,docker_storage_driver,package_update,package_availability,package_version
openshift_disable_check=docker_image_availability


#OpenShift Base configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# deployment type valid values are origin, online, atomic-enterprise, and openshift-enterprise
openshift_deployment_type=openshift-enterprise

# Specify the generic release of OpenShift to install. This is used mainly just during installation, after which we
# rely on the version running on the first master. Works best for containerized installs where we can usually
# use this to lookup the latest exact version of the container images, which is the tag actually used to configure
# the cluster. For RPM installations we just verify the version detected in your configured repos matches this
# release.
openshift_release="3.11"
openshift_version={{ ocp_version }}
openshift_pkg_version=-{{ ocp_version }}
openshift_image_tag=v{{ ocp_version }}
#=======================================================================

#Docker and cri-o Settings
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Install and run cri-o.
#openshift_use_crio=True
#openshift_use_crio_only=True
# The following two variables are used when openshift_use_crio is True
# and cleans up after builds that pass through docker. When openshift_use_crio is True
# these variables are set to the defaults shown. You may override them here.
# NOTE: You will still need to tag crio nodes with your given label(s)!
# Enable docker garbage collection when using cri-o
#openshift_crio_enable_docker_gc=True
# Node Selectors to run the garbage collection
#openshift_crio_docker_gc_node_selector={'runtime': 'cri-o'}

# Docker Options
{% if insecure_registry %}
openshift_docker_options='--selinux-enabled --log-opt max-size=1M --log-opt max-file=3 --log-driver=json-file --signature-verification=False --insecure-registry {{ registry_hostname }}:5000'
openshift_docker_additional_registries={{ registry_hostname }}:5000
openshift_docker_insecure_registries={{ registry_hostname }}:5000
openshift_docker_blocked_registries=registry.access.redhat.com,docker.io,registry.redhat.io
openshift_master_image_policy_allowed_registries_for_import=["{{ registry_hostname }}:5000"]
oreg_url={{ registry_hostname }}:5000/openshift3/ose-${component}:${version}
osm_etcd_image={{ registry_hostname }}:5000/rhel7/etcd:3.2.22
{% else %}
openshift_docker_options='--selinux-enabled --log-opt max-size=1M --log-opt max-file=3 --log-driver=json-file --signature-verification=False'
oreg_auth_user=admin
oreg_auth_password="{{ registry_pw }}"
oreg_url={{ registry_hostname }}:5000/openshift3/ose-${component}:${version}
{% endif %}
#=======================================================================

#Disconnected Registry Settings
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#oreg_url=registry.redhat.io/openshift3/ose-${component}:${version}
#oreg_url_master={{ registry_hostname }}/openshift3/ose-${component}:${version}
#oreg_url_node={{ registry_hostname }}/openshift3/ose-${component}:${version}
openshift_examples_modify_imagestreams=true
# Add insecure and blocked registries to global docker configuration
# In this case we need to add the image_registry
#openshift_docker_additional_registries={{ registry_hostname }}:5000

# If using a disconnected, unsecure registry enable this setting
#openshift_docker_insecure_registries={{ registry_hostname }}:5000

#Block all registries except the disconnected registry.
# Use this setting when talking to a disconnected registry
#openshift_docker_blocked_registries=registry.access.redhat.com,docker.io,registry.redhat.io
# Use this setting when talking to registry.redhat.io
#openshift_docker_blocked_registries=docker.io

# Configure imagePolicyConfig in the master config
# See: https://docs.okd.io/latest/admin_guide/image_policy.html
#openshift_master_image_policy_config={"maxImagesBulkImportedPerRepository": 3, "disableScheduledImport": true}
# This setting overrides allowedRegistriesForImport in openshift_master_image_policy_config. By default, all registries are allowed.
#openshift_master_image_policy_allowed_registries_for_import=["{{ registry_hostname }}:5000"]


# If the image for etcd needs to be pulled from anywhere else than registry.redhat.io, e.g. in
# a disconnected and containerized installation, use osm_etcd_image to specify the image to use:
#osm_etcd_image={{ registry_hostname }}/rhel7/etcd-3.2.28
#=======================================================================

# Registry Auth Settings
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# If oreg_url points to a registry requiring authentication, provide the following:
# https://docs.openshift.com/container-platform/3.11/install_config/configuring_red_hat_registry.html#install-config-configuring-red-hat-registry
#oreg_auth_user=admin
#oreg_auth_password="{{ registry_pw }}"
#=======================================================================


# Auth Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

# LDAP (AD) Configuration
openshift_master_identity_providers=[{'name':'htpasswd_auth','login':'true','challenge':'true','kind':'HTPasswdPasswordIdentityProvider'}]
openshift_master_htpasswd_users={'admin':'{{ ocp_admin_pw }}', 'admin-pipeline':'{{ ocp_pipeline_pw_hash }}' }


# TIP This will only be in-place while we setup the cluster.
# htpasswd auth
# NOTE, currently this is integrated into the provider above with LDAP, DO NOT ENABLE THIS UNLESS YOU KNOW WHAT YOU'RE DOING!
#openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider'}]
# Defining htpasswd users (levelup-admin)
#=======================================================================


#LB & Hostname Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Native high availability cluster method with optional load balancer.
# If no lb group is defined, the installer assumes that a load balancer has
# been preconfigured. For installation the value of
# openshift_master_cluster_hostname must resolve to the load balancer
# or to one or all of the masters defined in the inventory if no load
# balancer is present.
public_lb={{ public_lb }}
internal_lb={{ internal_lb }}
openshift_master_cluster_method=native
openshift_master_cluster_public_hostname={{ openshift_master_cluster_public_hostname }}
openshift_master_cluster_hostname={{ internal_lb }}

openshift_master_overwrite_named_certificates=true
# Detected names may be overridden by specifying the "names" key
#openshift_master_named_certificates=[{"certfile": "/tmp/ocp_masters.pem", "keyfile": "/tmp/ocp_masters.key", "names": ["{{ default_route }}"], "cafile": "/tmp/ocp_masters_chain.crt"}]

# default subdomain to use for exposed routes
default_route={{ default_route }}
openshift_master_default_subdomain={{ openshift_master_default_subdomain }}

#=======================================================================

# Firewall configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# # You can open additional firewall ports by defining them as a list. of service
# # names and ports/port ranges for either masters or nodes.
openshift_node_open_ports=[{"service":"cockpit","port":"9090/tcp"},{"service":"nodeexporter","port":"9100/tcp"},{"service":"haproxy","port":"1936/tcp"}]

# Use firewalld per doc
os_firewall_use_firewalld=True
#=======================================================================

#Router Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# default project node selector
osm_default_node_selector='node-role.kubernetes.io/compute=true'

# OpenShift Router Options
openshift_hosted_router_selector='node-role.kubernetes.io/infra=true'
openshift_hosted_router_replicas=3

# Router certificate (optional)
# Provide local certificate paths which will be configured as the
# router's default certificate.
#openshift_hosted_router_certificate={"certfile": "/tmp/ocp_apps.pem", "keyfile": "/tmp/ocp_apps.key", "cafile": "/tmp/ocp_apps_chain.crt"}
#=======================================================================


#Registry Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Registry selector (optional)
# Registry will only be created if nodes matching this label are present.
openshift_hosted_registry_selector='node-role.kubernetes.io/infra=true'
openshift_hosted_registry_replicas=2

# Registry Storage Options
#
# TODO Update Me
# AWS S3
# S3 bucket must already exist.
openshift_hosted_registry_storage_kind=object
openshift_hosted_registry_storage_provider=s3
openshift_hosted_registry_storage_s3_encrypt=true
openshift_hosted_registry_storage_s3_bucket={{ s3_bucket_name }}
openshift_hosted_registry_storage_s3_region={{ region }}
# TODO Update
# These can be placed in ENVs if necessary.
#openshift_hosted_registry_storage_s3_kmskeyid=aws_kms_key_id
#openshift_hosted_registry_storage_s3_accesskey=REMOVED
#openshift_hosted_registry_storage_s3_secretkey=REMOVED
# End Update
openshift_hosted_registry_storage_s3_chunksize=26214400
openshift_hosted_registry_storage_s3_rootdirectory=/registry
openshift_hosted_registry_pullthrough=true
openshift_hosted_registry_acceptschema2=true
openshift_hosted_registry_enforcequota=true

#=======================================================================

#Metrics Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
#openshift_metrics_hawkular_hostname=hawkular-metrics.{{ openshift_master_default_subdomain }}
#openshift_metrics_install_metrics=true
#openshift_metrics_hawkular_nodeselector={"node-role.kubernetes.io/infra":"true"}
#openshift_metrics_cassandra_nodeselector={"node-role.kubernetes.io/infra":"true"}
#openshift_metrics_heapster_nodeselector={"node-role.kubernetes.io/infra":"true"}
#openshift_metrics_duration=7
#openshift_metrics_cassandra_storage_type=dynamic

#
# Option C - Dynamic -- If openshift supports dynamic volume provisioning for
# your cloud platform use this.
#openshift_metrics_storage_kind=dynamic
#openshift_metrics_storage_volume_size=60Gi
#=======================================================================

#Cluster Monitoring
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Cluster monitoring is enabled by default, disable it by setting
openshift_cluster_monitoring_operator_install=true
#
# Cluster monitoring configuration variables allow setting the amount of
# storage requested through PersistentVolumeClaims.
#
#openshift_cluster_monitoring_operator_prometheus_storage_enabled=true
#openshift_cluster_monitoring_operator_prometheus_storage_capacity="50Gi"
# TODO set the storageclass name here first.
#openshift_cluster_monitoring_operator_prometheus_storage_class_name=
#openshift_cluster_monitoring_operator_alertmanager_storage_enabled=true
#openshift_cluster_monitoring_operator_alertmanager_storage_capacity="5Gi"
# TODO set the storageclass name here first.
#openshift_cluster_monitoring_operator_alertmanager_storage_class_name=
#openshift_cluster_monitoring_operator_alertmanager_config=
#=======================================================================



#Logging Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

# Currently logging deployment is disabled by default, enable it by setting this
# These following 2 lines shoudl be uncommented for the initial install.  Once logging is manually
# configured to the local storage infra node they should be commented back for any subsequent install runs
# On fresh deploy change this to true
openshift_logging_install_logging=true
openshift_logging_master_public_url=https://{{ public_lb }}:443
openshift_logging_es_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_kibana_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_curator_nodeselector={"node-role.kubernetes.io/infra":"true"}
openshift_logging_curator_default_days=15
#openshift_logging_es_pvc_size=100Gi
openshift_logging_es_memory_limit=8G

# Option C - Dynamic -- If openshift supports dynamic volume provisioning for
# your cloud platform use this.
#openshift_logging_storage_kind=dynamic
#=======================================================================



#SDN Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Configure the multi-tenant SDN plugin (default is 'redhat/openshift-ovs-subnet')
#os_sdn_network_plugin_name='redhat/openshift-ovs-multitenant'
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

# TODO update with correct CIDRs
# Configure SDN cluster network and kubernetes service CIDR blocks. These
# network blocks should be private and should not conflict with network blocks
# in your infrastructure that pods may require access to. Can not be changed
# after deployment.
##Pod Network
osm_cluster_network_cidr=10.224.0.0/16
##Service Network
openshift_portal_net=10.225.0.0/16

# Configure number of bits to allocate to each host's subnet e.g. 9
# would mean a /23 network on the host.
# When upgrading or scaling up the following must match whats in your master config!
#  Inventory: master yaml field
#  osm_host_subnet_length:  hostSubnetLength
# When installing osm_host_subnet_length must be set. A sane example is provided below.
osm_host_subnet_length=9
#=======================================================================


#Master & Node Configuration
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Configure master API and console ports.
openshift_master_api_port=443
openshift_master_console_port=443


# Enable service catalog
openshift_enable_service_catalog=true

# Enable template service broker (requires service catalog to be enabled, above)
template_service_broker_install=true
openshift_template_service_broker_namespaces=['openshift']

# Override master and node servingInfo.minTLSVersion and .cipherSuites
# valid TLS versions are VersionTLS10, VersionTLS11, VersionTLS12
# example cipher suites override, valid cipher suites are https://golang.org/pkg/crypto/tls/#pkg-constants
openshift_master_min_tls_version=VersionTLS12
#openshift_master_cipher_suites=['TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256', '...']
openshift_node_min_tls_version=VersionTLS12
#openshift_node_cipher_suites=['TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256', '...']
#=======================================================================

#Other Options
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# Install the openshift examples
#openshift_install_examples=true

# Enable unsupported configurations, things that will yield a partially
# functioning cluster but would not be supported for production use
openshift_enable_unsupported_configurations=false

# Add a trusted CA to all pods, copies from the control host, may be multiple
# certs in one file
#openshift_additional_ca=/root/ocp-configs/upsc.up.hmchpc.mil.ca-bundle.pem

# default storage plugin dependencies to install, by default the ceph and
# glusterfs plugin dependencies will be installed, if available.
# osn_storage_plugin_deps=['glusterfs','iscsi']
#=======================================================================

#AWS Config
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
openshift_cloudprovider_kind=aws
#### To use this setting need to tag all openshift EC2
openshift_clusterid={{ openshift_clusterid }}
#Three options.
#1) Set the keys here
#2) Set the key in ENV vars, run the install, then clear the vars
#3) Assign the IAM roles to each node in the cluster and comment the 4 lines below.
#openshift_cloudprovider_aws_access_key=
#openshift_cloudprovider_aws_secret_key=
{% if cloud_environment | default('aws') != 'cloud1' %}
openshift_cloudprovider_aws_access_key="{{ aws_access_key }}"
openshift_cloudprovider_aws_secret_key="{{ aws_secret_key }}"
{% endif %}
#=======================================================================

#Default Storage Class Config
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
# StorageClass
openshift_storageclass_name=gp2
openshift_storageclass_parameters={'type': 'gp2', 'encrypted': 'true'}
openshift_storageclass_reclaim_policy="Delete"
#=======================================================================

#Node Groups
#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
openshift_node_groups=[{'name': 'node-config-master',  'labels': ['node-role.kubernetes.io/master=true' ],'edits': [{ 'key': 'kubeletArguments.kube-reserved','value':['cpu=100m,memory=128M']}, { 'key': 'kubeletArguments.system-reserved','value': ['cpu=100m,memory=256M']},{ 'key': 'kubeletArguments.pods-per-core','value': ['10']},{ 'key': 'kubeletArguments.max-pods','value': ['250']},{ 'key': 'kubeletArguments.maximum-dead-containers','value': ['5']},{ 'key': 'kubeletArguments.maximum-dead-containers-per-container','value': ['1']},{ 'key': 'kubeletArguments.image-gc-high-threshold','value': ['80']},{ 'key': 'kubeletArguments.image-gc-low-threshold','value': ['60']}]},{'name': 'node-config-infra',   'labels': ['node-role.kubernetes.io/infra=true'  ],'edits':[{ 'key': 'kubeletArguments.kube-reserved','value': ['cpu=100m,memory=128M']},{ 'key': 'kubeletArguments.system-reserved','value': ['cpu=100m,memory=256M']},{ 'key': 'kubeletArguments.pods-per-core','value': ['10']},{ 'key': 'kubeletArguments.max-pods','value': ['250']},{ 'key': 'kubeletArguments.maximum-dead-containers','value': ['5']},{ 'key': 'kubeletArguments.maximum-dead-containers-per-container','value': ['1']},{ 'key': 'kubeletArguments.image-gc-high-threshold','value': ['80']},{ 'key': 'kubeletArguments.image-gc-low-threshold','value': ['60']}]},{'name': 'node-config-compute', 'labels': ['node-role.kubernetes.io/compute=true'],'edits':[{ 'key': 'kubeletArguments.kube-reserved','value': ['cpu=100m,memory=128M']},{ 'key': 'kubeletArguments.system-reserved','value': ['cpu=100m,memory=256M']},{ 'key': 'kubeletArguments.pods-per-core','value': ['10']},{ 'key': 'kubeletArguments.max-pods','value': ['250']},{ 'key': 'kubeletArguments.maximum-dead-containers','value': ['5']},{ 'key': 'kubeletArguments.maximum-dead-containers-per-container','value': ['1']},{ 'key': 'kubeletArguments.image-gc-high-threshold','value': ['80']},{ 'key': 'kubeletArguments.image-gc-low-threshold','value': ['60']}]},{'name': 'node-config-master-infra',  'labels': ['node-role.kubernetes.io/infra=true' ,'node-role.kubernetes.io/master=true' ]},{'name': 'node-config-all-in-one',  'labels': ['node-role.kubernetes.io/infra=true', 'node-role.kubernetes.io/master=true' ,'node-role.kubernetes.io/compute=true' ]}]
#=======================================================================

## The groups here are not used by the install, for admin ease ##

[master-infra:children]
masters
infra

[bastion]
